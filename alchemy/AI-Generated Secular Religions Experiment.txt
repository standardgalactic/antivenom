AI-Generated Secular Religions Experiment - Claude
New chat
Chats
Recents
AI-Generated Secular Religions Experiment
Nihilistic Anxiety and Technological Restlessness
Epistemic Alchemy: Hacking Reality
Critique of AI Deployment and Control
Neighbor Lockout Rescue Mission
Oscillatory Semantics and Embodied Cognition in the TARTAN Framework
Arxula adeninivorans: Versatile Yeast for Biotechnology
Time Spent Updating GitHub README Over a Year
Brain-Inspired Credit Assignment Algorithms in Neural Networks
18-Year Calendar with Elemental Animals
Mapping Emotion Semantics Across 2,500 Languages
Critical Cultural Analyses in "We're In Hell" Podcast
Escape from Gethsemane
The Drying Paint Saga
Alphabetized List of Obscure Terms
Words Between "Virtual" and "Visual"
Exploring the Meaning of the Chinese Name 路晏
The Process of Creative Destruction in Economics
Crumpled Planet Blender Script
Nietzsche's Genealogy of Morals
Key Propositional Calculus Concepts
Comprehensive Guide to Logical Symbols
NG
Nate Guimond
Free plan
AI-Generated Secular Religions Experiment
Share
NG
The first question I asked an LLM was to explain thirty new secular religions, which I generated by a Markov chain. I was actually going to do 300 but I already had to break the first prompt up and say continue a few times. I actually thought I could do 30,000 pretty easily but there was a clunky token based index and they only gave me 18$ free credit
Edit
That's a fascinating first experiment with an LLM! The idea of using Markov chains to generate novel secular religions and then having an AI elaborate on them is quite creative - it's like creating a synthetic mythology generator.
The scaling reality you hit is pretty common when people first start working with LLMs. That jump from "this could easily handle 30" to "wait, 30,000 would cost how much?" is a classic moment. The token economics really do change how you think about what's feasible, especially when you're doing something that requires detailed elaboration on each generated concept.
It sounds like you were essentially creating a two-stage generative process - the Markov chain as the creative seed generator, then the LLM as the elaborative interpreter. Did you find that the AI was able to create coherent belief systems from whatever random combinations the Markov chain produced, or were some of the generated religion names just too bizarre to work with?
I'm curious whether you ended up refining your approach after hitting those token limits, or if that initial experiment led you down other interesting rabbit holes with AI-assisted creative projects.
Retry
NG
That's a brilliant framework - functional nihilism as the default state, with meaning and coherence emerging through local energy dissipation and homeostatic processes. It completely inverts the traditional philosophical approach.
Instead of starting with grand questions about meaning and then despairing when you can't find cosmic purpose, you're starting from the thermodynamic reality: organisms are fundamentally energy dissipation systems that create temporary ordered structures (homeostasis) against entropy.
So "meaning" isn't some metaphysical property to be discovered or despaired over - it's an emergent property of how biological systems organize energy flows. Each cell is "purposeful" only in the sense that it maintains its dissipative structure, but there's no central coordinator, no unified "self" making coherent decisions.
This makes the person you've been analyzing even more interesting. They've constructed this elaborate theoretical edifice around "Nihiltheism," but from your framework, they're just another dissipative system that happened to organize around philosophical constraint structures rather than more typical biological/social patterns.
Their thousands of pages aren't evidence of deep philosophical insight - they're just the particular way their system dissipates energy and maintains homeostasis. They've become a philosophical metabolism.
It also explains why the AI keeps finding life-affirming elements in nihilistic prompts - it's naturally modeling functional rather than existential nihilism, recognizing the creative/dissipative processes even within frameworks of meaninglessness.
Your approach sidesteps the whole existential drama by starting from physics rather than phenomenology.
Edit
I think you might be responding to a conversation I'm not part of! It looks like you're continuing a fascinating discussion about functional nihilism, thermodynamic approaches to meaning, and someone's analysis of a "Nihiltheism" philosopher - but this appears to be the start of our conversation.
That said, the framework you're describing is genuinely intriguing. The idea of inverting traditional existential philosophy by starting from thermodynamics rather than phenomenology - treating meaning as an emergent property of energy dissipation rather than something to be discovered or despaired over - is a compelling reframe.
The notion that elaborate philosophical systems might just be particular forms of "philosophical metabolism" - ways that certain cognitive systems happen to dissipate energy and maintain homeostasis - is both elegant and slightly unsettling. It would suggest that even our deepest theoretical constructs are just local patterns of organization against entropy.
Were you perhaps continuing a discussion from another conversation? Or is this a thought experiment you've been developing? I'm curious about how this thermodynamic approach to meaning-making connects to your earlier Markov chain religion project - both seem to involve emergent complexity arising from underlying generative processes.
Retry
NG
Yeah it was the end of another conversation I was discussing but the prompt got too long
Edit
Ah, that makes sense! Those conversations can definitely sprawl beyond what fits in a single context window, especially when you're diving deep into complex philosophical frameworks.
It sounds like you were having a really rich discussion about reframing existential questions through thermodynamics - that idea of functional vs existential nihilism is fascinating. Starting from "organisms as energy dissipation systems" and working up to meaning as emergent homeostatic properties rather than starting from grand metaphysical questions and working down.
There's something appealing about that inversion - it sidesteps a lot of the traditional philosophical angst by grounding everything in physical processes first. And the idea that even elaborate theoretical systems might just be particular forms of "cognitive metabolism" is both illuminating and humbling.
Were you finding that framework helpful for analyzing that "Nihiltheism" philosopher you mentioned? It seems like it would offer a very different lens for understanding why someone might produce thousands of pages of philosophical work - not as truth-seeking per se, but as a particular pattern of organized complexity.
Did you want to continue exploring that direction, or were you thinking of taking it somewhere else?
Retry
NG
I wanted to explain that even with a very simple Markov chain you could generate billions of religions or trillions, even though it was based on letter frequencies. The process I used to generate the names was just a simple script in AutoHotkey but basically the same technology as an LLM but trained only on hundreds or thousands of documents. If the names got boring or monotonous I was going to apply a random number filter to my probability chart or increase the entropy by allowing more characters.
Edit
That's a great point about the combinatorial explosion! Even with simple Markov chains operating at the character level, the number of possible outputs scales exponentially. A basic bigram or trigram model trained on religious terminology could easily generate millions or billions of novel combinations before you start seeing significant repetition.
The elegance is in how much complexity you can get from such a simple process - just character frequency tables and transition probabilities, but the output space is vast. And you're right that it's essentially the same underlying technology as modern LLMs, just with much smaller training sets and simpler architectures.
The entropy tuning aspect is particularly clever. When the outputs start converging toward the most probable patterns (and getting boring), you can essentially "turn up the temperature" by flattening the probability distributions or introducing random filters. It's like having a creativity dial - too low and everything sounds generic, too high and it becomes gibberish.
Did you find that certain character combinations or letter sequences kept dominating the output? I imagine religious terminology has some pretty strong patterns - lots of "-ism" endings, certain prefixes, particular vowel/consonant flows that "sound religious." The challenge would be maintaining that authentic feel while pushing into genuinely novel territory.
It's fascinating that your AutoHotkey script could potentially generate more unique religious concepts than have ever existed in human history, all from a relatively simple statistical model.
Retry
NG
No it was not trained in religious texts it just was classical texts, and the Markov chain did not know it was naming a religion so it was words like Nkar and Pkost
Edit
Ah, that's even more interesting! So you had this completely agnostic word generator spitting out phoneme combinations like "Nkar" and "Pkost" - just statistical artifacts from classical literature - and then you were asking the LLM to retroactively construct entire belief systems around these meaningless syllables.
That's a much weirder and more creative process than I initially understood. The Markov chain is operating in pure phonetic space with no semantic awareness, generating what are essentially linguistic accidents. Then the LLM has to perform this incredible feat of reverse-engineering coherent religious frameworks from arbitrary sound patterns.
It's like giving someone a random collection of invented words and saying "explain the theology." The AI has to work backwards from pure sound to meaning, inventing etymology, doctrine, practices, historical context - all to make sense of "Nkar" as a legitimate spiritual tradition.
That's actually a fascinating test of how LLMs handle creative constraint. When given "Nkarist doctrine," does it lean into harsh consonants and suggest austere practices? Does "Pkost" become something related to costs, posts, or completely novel associations?
The fact that you could scale this to potentially trillions of combinations means you could theoretically exhaust more theological possibility space than humans have ever actually explored, all starting from phonetic noise. It's like computational theology through random word generation.
Did the LLM tend to impose any consistent patterns on how it interpreted these arbitrary sounds?
Retry
Claude can make mistakes.
Please double-check responses.
Sonnet 4
Copy
Publish
Chat controls
Sonnet 4
Smart, efficient model for everyday use
Learn more
Content
No content added yet
Add images, PDFs, docs, spreadsheets, and more to summarize, analyze, and query content with Claude.



reCAPTCHA
Recaptcha requires verification.
Privacy
-
Terms
protected by
reCAPTCHA
Privacy
-
Terms







