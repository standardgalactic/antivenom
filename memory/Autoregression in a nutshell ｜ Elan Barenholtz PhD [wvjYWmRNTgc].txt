Cognition itself is basically autoregressive generation so what I mean by that is that the
large language models like things like ChatGPT do this thing where they're they're a trained
network that's that has learned to just produce the next token in the case of language it's just
the next word typically it's just the next word and then after produce the next word it uses that
to feed that in as as its next input and it builds up a larger and larger input and and but does this
stepwise so it's just taking an input producing the next token tacking that on to the previous
input and then producing the next token again and then just does it successfully and what we see
from the large language models is this seems to actually solve language but to me this was a kind
of epiphany that perhaps this is what cognition more broadly is that what our brain is is a trained
network that has learned over the course of our lifetime and experience what is the appropriate
next token whether it's uh it could be language but we it could be in other modalities as well
when we're thinking visually well we might produce the next uh the next visual image based on the
images that we uh have thought about uh in in the past in the recent past um and I'm sort of going
after this aggressively uh as kind of like proved me wrong Occam's razor that this might account for
all of cognition that what we're doing when we're thinking and when we're reasoning is we're really
just doing next token generation um and that knowledge and memories and all of these things
are really just the trained models
