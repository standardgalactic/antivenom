\documentclass[12pt]{article}

\usepackage[margin=1in]{geometry}
\usepackage{setspace}
\usepackage{csquotes}
\usepackage{hyperref}
\usepackage{amsmath, amssymb}
\usepackage{fontspec}

\setstretch{1.25}

\title{\textbf{The Commodification of Categories}\\
\large Platform Economics and the Collapse of Epistemic Gatekeeping}
\author{Flyxion }
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
This essay argues that Audible, a paid audiobook platform operated by Amazon, has systematically abandoned minimal standards of epistemic gatekeeping by monetizing fraudulent and non-book content under the category of Science and Engineering. Many such listings consist primarily of astrological advertisements, direct contact information, or claims of supernatural, medical, or legal efficacy, and bear no meaningful relationship to scientific inquiry. Their persistence at scale is not adequately explained as incidental low-quality content, but instead reflects a structural failure of categorization, verification, and user protection within a platform explicitly marketed as a knowledge service. The consequence is not mere inconvenience to readers, but institutional harm: the erosion of scientific categories as meaningful signals, the exploitation of unsuspecting customers, and the transformation of a curated library into a venue for reputation-laundered advertising.
\end{abstract}

\newpage

\begin{quote}
\emph{“The problem is not that television presents us with entertaining subject matter but that all subject matter is presented as entertaining, which is another issue altogether.”}  
--- Neil Postman, \emph{Amusing Ourselves to Death} (1985)
\end{quote}

\vspace{1em}

\section{Introduction: The Expectation of a Knowledge Platform}

A paid platform that presents itself as a repository of scientific and technical knowledge enters into an implicit contract with its users. When a reader browses a category labeled ``Science \& Engineering,'' they are not merely navigating metadata. They are relying on the platform’s claim that the material presented bears some meaningful relationship to scientific inquiry, technical practice, or scholarly communication.

That expectation is not naïve. It is foundational. Without it, the category itself is meaningless.

Yet today, Audible’s Science \& Engineering listings routinely surface content that is transparently unrelated to science: tantric astrology advertisements, black magic services, immigration and visa claims, and listings whose primary payload is a WhatsApp or phone number. These are not edge cases. They appear at scale, persist over time, and occupy discovery surfaces such as ``New Releases.''

This essay contends that this situation is neither accidental nor benign.

\section{Not Spam, Not Noise: Fraudulent Content as a Business Input}

It is tempting to describe these listings as ``spam.'' That framing is inadequate.

Spam implies an adversarial intrusion resisted by the platform. What is visible on Audible instead is tolerance, persistence, and monetization. These listings are uploaded, categorized, indexed, and sold. Audible receives payment—directly or via subscription allocation—and provides reputational cover through its brand and taxonomy.

The distinction matters. A platform that unknowingly hosts spam is negligent. A platform that knowingly profits from fraudulent listings while suppressing user feedback mechanisms is complicit.

The presence of phone numbers, explicit service solicitation, medical and legal claims, and supernatural guarantees would disqualify content from most marketplaces. Their continued availability in a paid science category indicates a deliberate lowering of standards rather than a failure to detect abuse.

\section{The Collapse of Categorization as Epistemic Infrastructure}

Categories are not cosmetic. They are epistemic infrastructure.

To label something ``Science \& Engineering'' is to assert that it participates—however loosely—in norms of evidence, explanation, or technical practice. When that label is applied indiscriminately, it ceases to function. Science becomes a decorative term, emptied of meaning and repurposed as a traffic funnel.

This collapse harms more than experienced readers, who may learn to ignore browsing entirely. It disproportionately harms new or less technically literate users, who are more likely to mistake platform presence for legitimacy. In this way, Audible’s categorization practices actively facilitate deception.

\section{Blocked Recourse and the Suppression of Accountability}

Audible provides no effective mechanism to report such listings prior to consumption. Reviews are gated behind listening requirements, forcing users to expend time and attention—and to generate engagement metrics—before registering objections. This design choice converts critique into participation and ensures that the most obvious abuse never aggregates into actionable signals.

The absence of reporting is not neutral. It functions as a form of institutional insulation, preventing internal metrics from reflecting the scale of the problem and allowing the platform to claim plausible ignorance.

\section{From Enshittification to Misrepresentation}

Critiques of platform capitalism often focus on gradual service degradation: worse recommendations, higher prices, increased lock-in. What is occurring here is more severe. Audible is not merely offering a worse product; it is misrepresenting what it sells.

When a monopoly platform sells fraudulent content under the banner of science, the harm is epistemic as well as economic. Knowledge categories are devalued, trust is eroded, and the distinction between inquiry and superstition is blurred in exchange for marginal revenue.

This is not an accidental outcome of scale. It is a choice.

\section{Conclusion: The Responsibility of a Paid Knowledge Monopoly}

Audible is not an open forum. It is not a peer-to-peer exchange. It is a paid, curated service operating under the authority of one of the largest corporations in the world. With that position comes responsibility.

The continued sale of overtly fraudulent content in scientific categories represents a failure of that responsibility. More troublingly, it suggests a willingness to trade epistemic integrity for revenue while denying users meaningful avenues for objection.

If science is to remain distinguishable from its imitations, platforms that profit from its distribution must be held to standards higher than indifference.

\section{Monetization Without Vetting: When Revenue Overrides Legitimacy}

It is important to be explicit about what is at stake. Audible is not merely hosting this material; it is monetizing it. Whether through direct purchases, subscription credit allocation, or catalog-level financial arrangements, money flows from customers to Audible as a result of these listings. The platform benefits economically from their presence, while bearing little to none of the downstream risk.

This fact sharply distinguishes the present case from traditional moderation failures. In a neutral hosting scenario, harmful or misleading content represents an external cost imposed on the platform. Here, by contrast, fraudulent listings function as revenue-generating inputs. The incentive to remove them is therefore structurally weak, while the incentive to tolerate them is persistent.

The absence of meaningful vetting is not defensible at Audible’s scale. Audible is not a marginal or experimental service; it is the dominant audiobook platform in a highly concentrated market. It already enforces strict controls over digital rights management, regional availability, pricing, and subscription usage. The claim that basic content validation—such as rejecting listings that consist of phone numbers, service advertisements, or supernatural guarantees—would be infeasible is implausible.

What is instead revealed is a hierarchy of priorities. Technical and contractual controls that protect revenue streams are enforced rigorously. Controls that protect epistemic integrity are treated as optional. This asymmetry exposes the underlying logic of the platform: knowledge is not the product being protected; throughput is.

In this context, Audible’s continued acceptance of fraudulent pseudo-scientific content cannot be understood as oversight. It is the predictable outcome of a system in which the reputational capital of science is exploited to sell access, while the costs of deception are diffused across users who lack both visibility and recourse. The platform profits from the appearance of legitimacy while disclaiming responsibility for its substance.

Such behavior does not merely degrade quality. It undermines the very distinction between curated knowledge and opportunistic advertising. When a paid science category becomes indistinguishable from a classified ad board, the platform ceases to function as a library at all. It becomes a broker of credibility, selling trust without regard for what it certifies.

\section{Consumer Harm and Asymmetric Risk}

The harms produced by this system are not hypothetical. They are asymmetric, predictable, and borne almost entirely by users. Audible incurs little reputational or financial risk from hosting fraudulent listings, while customers—particularly those less familiar with scientific norms or platform failure modes—face real losses of money, time, and trust.

For experienced readers, the primary cost is discovery collapse. Browsing becomes futile, categories become unreliable, and the act of seeking new scientific material is replaced by defensive filtering and prior knowledge. While frustrating, these users are at least equipped to recognize the deception.

For others, the harm is more direct. The presence of a listing on Audible, categorized as Science \& Engineering and sold within a paid ecosystem, carries an implicit endorsement. It signals legitimacy. Unsuspecting customers may reasonably infer that content appearing under such a label has passed minimal checks for relevance and good faith. When that inference proves false, the platform has facilitated deception under its own authority.

This asymmetry is compounded by the design of Audible’s subscription model. Credits obscure the price signal of individual purchases, lowering resistance to experimentation and increasing the likelihood that fraudulent content is acquired casually. Once acquired, the absence of effective reporting mechanisms prevents meaningful redress. The loss is absorbed silently by the user, while the platform retains the benefit.

Crucially, this harm is not accidental. It follows directly from institutional choices: to allow monetization without vetting, to block pre-consumption reporting, and to treat categorization as a marketing affordance rather than a semantic commitment. In doing so, Audible shifts all epistemic and economic risk downstream, onto the very users whose trust sustains the platform.

A system that reliably transfers harm away from itself while capturing revenue cannot plausibly claim neutrality. It is optimized for extraction under conditions of informational asymmetry. That such a system operates within a domain explicitly associated with scientific credibility makes the outcome more, not less, severe.

\section{Monopoly Power and the Absence of Exit}

Audible’s position in the audiobook market fundamentally alters the ethical and practical stakes of its behavior. This is not a competitive environment in which dissatisfied users can easily discipline the platform by leaving. Audible is the dominant distributor of audiobooks in English, deeply integrated into Amazon’s ecosystem, and supported by exclusivity agreements that shape what content is available elsewhere.

For long-term users, the cost of exit is substantial. Personal libraries may contain hundreds of titles accumulated over years, often revisited multiple times. These collections are locked behind proprietary digital rights management, rendering them non-transferable. The platform thus benefits from a form of captivity: users remain not because the service is exemplary, but because leaving would require abandoning significant sunk value.

This lack of exit undermines one of the primary mechanisms by which markets are supposed to correct abuse. When users cannot realistically leave, the platform faces reduced pressure to maintain standards. Discovery quality can collapse, categorization can lose meaning, and fraudulent content can proliferate without triggering mass departure.

Monopoly conditions also magnify harm. A small platform tolerating dubious content is a localized problem. A dominant platform doing so reshapes norms across an entire medium. When Audible blurs the line between scientific material and superstition, it does not merely affect its own catalog; it redefines expectations for what an audiobook platform is allowed to sell as knowledge.

In this context, appeals to user choice ring hollow. Audible’s market power carries with it a responsibility to uphold baseline epistemic standards precisely because users lack effective alternatives. To abdicate that responsibility while continuing to extract revenue is not a neutral business decision. It is an exploitation of structural dependency.

\section{From Negligence to Institutional Misrepresentation}

At a certain scale, persistent failure ceases to be accidental. When a platform repeatedly allows content that is transparently fraudulent, irrelevant, or deceptive to occupy a paid scientific category, the appropriate description is no longer negligence but misrepresentation.

Audible presents itself as a curated audiobook service. Its marketing emphasizes quality, credibility, and discovery. Categories such as Science \& Engineering are not neutral filing cabinets; they are claims about the nature of the content within them. To sell access to such categories while knowingly tolerating material that bears no relationship to science is to misstate what is being offered.

This misrepresentation operates at two levels. First, individual listings mislead customers by masquerading as books while functioning as advertisements or service solicitations. Second, the platform itself misleads users by presenting the category as meaningful when it no longer is. The latter is the more serious offense, because it implicates the platform’s own authority and branding.

Crucially, Audible is not a passive intermediary. It controls onboarding, pricing, categorization, distribution, and access. It enforces restrictions rigorously when revenue protection is at stake. That it fails to enforce even minimal standards when epistemic integrity is at stake reveals the nature of the prioritization at work.

Institutional misrepresentation does not require explicit false statements. It arises when a system systematically creates false beliefs through its structure while benefiting from those beliefs. By continuing to profit from the appearance of scientific legitimacy while disclaiming responsibility for its content, Audible engages in exactly this form of deception.

When misrepresentation becomes structural, it cannot be corrected by individual vigilance. It requires institutional accountability. Absent that accountability, the platform ceases to be a trustworthy intermediary and becomes instead a conduit for epistemic fraud, protected by scale and insulated by design.

\section{The Normalization of Epistemic Fraud}

One of the most damaging consequences of Audible’s practices is not any single fraudulent listing, but the gradual normalization of epistemic fraud as an acceptable background condition. When overtly deceptive content persists without correction, it teaches users—implicitly but effectively—that categories cannot be trusted, that labels are ornamental, and that scientific credibility is merely a marketing aesthetic.

This normalization operates quietly. There is no announcement that standards have been lowered, no acknowledgment that vetting has ceased. Instead, users adapt. They stop browsing. They rely on prior knowledge. They assume that discovery surfaces are polluted by default. What appears, from the platform’s perspective, as stable engagement is in fact a form of resignation.

Such resignation is corrosive. It undermines the expectation that institutions devoted to knowledge will distinguish between inquiry and exploitation. Over time, this erosion does not merely inconvenience readers; it reshapes cultural norms. If a dominant platform treats astrology advertisements and scientific works as equivalent commodities, the distinction itself begins to appear arbitrary. The category of science is hollowed out from within.

This effect is especially pernicious because it is cumulative and asymmetric. Fraudulent actors gain visibility and revenue, while legitimate authors are buried under noise. Readers lose trust, but the platform retains plausible deniability. The damage accrues diffusely, making it easy to ignore and difficult to reverse.

Normalization is not neutrality. It is a form of endorsement distributed over time. By allowing epistemic fraud to persist as a background condition of its marketplace, Audible effectively signals that truthfulness, relevance, and good faith are optional. In doing so, it participates in the slow transformation of a knowledge platform into an attention market where credibility is no longer a criterion, only a costume.

\section{Selective Competence: Audible in the Context of Amazon’s Technical Capacity}

Any claim that Audible’s failures stem from technical limitation collapses when placed in the context of Amazon’s broader infrastructure. Amazon operates some of the most sophisticated computational and monitoring systems in existence. Through Amazon Web Services, the company provides large-scale fraud detection, anomaly analysis, pattern recognition, and automated enforcement tools to governments, financial institutions, and global enterprises. Through Amazon Prime, it manages complex logistics, recommendation systems, dynamic pricing, and rights enforcement across millions of products in real time.

Against this backdrop, the persistence of overtly fraudulent and low-quality content on Audible cannot plausibly be attributed to incapacity. The same corporation that can detect suspicious credit card activity within milliseconds, throttle abusive API usage, and optimize global supply chains is fully capable of identifying phone numbers embedded in titles, detecting mass-produced AI-generated books, flagging synthetic narration falsely presented as human, and identifying coordinated upload behavior indicative of abuse.

The contrast is instructive. Where Amazon’s revenue streams or legal exposure are directly threatened—as in payment fraud, infrastructure abuse, or copyright infringement—technical enforcement is swift and uncompromising. Where the harm is epistemic rather than immediately financial—such as the degradation of knowledge categories or the flooding of discovery surfaces with nonsense—enforcement becomes lax or nonexistent. This asymmetry reveals not a lack of ability, but a hierarchy of concern.

Audible’s tolerance of AI-generated slop books, synthetic narration billed as human performance, and industrial-scale low-effort genre flooding mirrors patterns already documented in Amazon’s ebook marketplace. In those contexts, the company has long permitted the proliferation of “how to get rich,” romance boilerplate, and algorithmically generated content, even while enforcing strict most-favored-nation clauses that prevent sellers from offering lower prices elsewhere. As Cory Doctorow has repeatedly observed, such clauses suppress competition while insulating Amazon from the consequences of declining quality.

The result is a marketplace optimized for throughput rather than meaning. Quantity overwhelms discernment. Visibility is captured by those who can generate content fastest, not those who contribute most. In this environment, astrology advertisements masquerading as science, formulaic romance novels generated at scale, and instructional books teaching others how to exploit the same system are not anomalies; they are predictable outputs.

The broader risk is cultural. When dominant platforms normalize the sale of pseudo-knowledge, machine-generated filler, and deceptive representations under the banner of books, the cumulative effect is not merely individual disappointment. It is a gradual dulling of collective standards. Attention is diverted from rigorous work to noise. Trust in categories erodes. The expectation that knowledge requires effort, expertise, or accountability weakens.

Amazon possesses both the technology and the institutional leverage to prevent this outcome. That it does not act consistently across its services suggests that the issue is not oversight, but prioritization. Where infrastructure integrity and revenue protection are concerned, Amazon demands precision. Where human understanding and epistemic quality are concerned, it tolerates collapse. In allowing this disparity to persist, Audible becomes not just a passive venue for low-quality content, but an active participant in a system that risks, over time, dulling the intellectual environment on which any genuine culture of knowledge depends.

\section{Categories, Liberal Education, and the Moral Economy of Knowledge}

The collapse of epistemic gatekeeping on platforms such as Audible is not an isolated technical failure. It reflects a deeper erosion of the role that categories play in liberal education and in the organization of knowledge more generally. Categories are not arbitrary labels; they are pedagogical commitments. To teach science, history, or philosophy is to induct learners into traditions of reasoning, evidence, and responsibility. When categories lose their meaning, education itself is hollowed out.

A liberal arts education is not defined by content alone, but by the disciplined separation of explanation from persuasion, inquiry from manipulation. Science is taught not merely to transmit facts, but to cultivate habits of skepticism, generalization, and ethical restraint. The humanities exist not to entertain, but to provide critical distance from power, myth, and impulse. When platforms collapse these distinctions in pursuit of revenue, they do not merely degrade a marketplace; they undermine the conditions under which education can function.

The normalization of pseudo-knowledge and manipulative content signals a shift in values. Greed is reframed as efficiency, extraction as innovation, and scale as merit. Institutions that blur the line between inquiry and exploitation are not disciplined or dismantled; they are rewarded. Public funds, subsidies, and market dominance are extended to platforms that externalize epistemic harm while internalizing profit.

Meanwhile, those engaged in the slow, necessary work of improving the human condition—artists, technicians, repair workers, educators, nurses, and researchers—operate under conditions of chronic precarity. They work month to month, often at personal cost, to maintain infrastructure, heal bodies, preserve culture, and transmit knowledge. Their labor depends on stable categories and shared standards. Without them, skill cannot be recognized, expertise cannot be trusted, and learning cannot accumulate.

The asymmetry is stark. Programmers and managers within platform institutions are compensated at levels that reflect the extraction of value rather than its creation, while the domains most urgently in need of intellectual investment—medicine, public health, energy systems, transportation, and ecological design—struggle to attract and support generalist thinkers capable of integrating knowledge across fields. A society that rewards the manipulation of attention more than the understanding of systems cannot plausibly claim to value intelligence.

What is required are not more techniques for persuasion, growth hacking, or algorithmic influence, but more people trained to think broadly and rigorously: scientists who understand ethics, engineers who understand history, and citizens capable of distinguishing explanation from promise. That capacity depends on categories retaining their meaning. When platforms commodify those categories into empty marketing signals, they do not merely fail their users; they contribute to a wider educational and moral collapse.

If knowledge is to remain something other than a costume worn by profit, institutions that mediate learning must be held to standards aligned with the purposes of liberal education. The alternative is a society rich in information but poor in understanding, optimized for manipulation rather than care, and increasingly incapable of addressing the material and medical realities upon which its survival depends.


\section{Counterexamples: Audiobooks as Instruments of Intellectual Amplification}

The degradation of Audible’s catalog is not inevitable, nor is it a consequence of the audiobook medium itself. On the contrary, there exist clear counterexamples that demonstrate how audio, when treated as a serious pedagogical instrument, can measurably increase understanding, skill, and intellectual autonomy.

The Michel Thomas language courses provide a paradigmatic case. These recordings do not merely present information; they are structured as guided cognitive processes. Learners are led through carefully staged reasoning, correction, and reinforcement, allowing them to internalize grammatical structure and vocabulary without memorization or homework. The success of this method demonstrates that audio can sustain complex, cumulative learning, even in domains traditionally thought to require visual notation or formal instruction. The limitation is not the medium, but the intent and rigor of its design.

This insight generalizes. If structured dialogue, error correction, and conceptual scaffolding can be delivered through audio for language acquisition, there is no principled barrier to extending similar methods to more advanced material. Mathematics, logic, scientific reasoning, and philosophy all admit of oral exposition when developed with care. The question is not whether such content can exist, but whether platforms choose to cultivate it.

The Teaching Company, known for its \emph{Great Courses} series, offers a second counterexample. These courses are developed by award-winning educators selected for both subject-matter expertise and pedagogical skill. Their lectures are explicitly designed to explain, not to impress or manipulate. Crucially, they direct listeners toward rational frameworks: how economic systems function, why certain explanations succeed or fail, how historical events unfold under structural constraints, and what constitutes evidence in different fields of inquiry. They aim not to promise wealth, luck, or destiny, but to increase the listener’s capacity to reason.

These examples reveal what is at stake in Audible’s toleration of pseudo-content. Audiobooks can function as tools of intellectual amplification, enabling sustained engagement with difficult ideas. They can increase linguistic competence, conceptual clarity, and epistemic confidence. To replace this potential with astrology advertisements, superstition, and formulaic promises of success is not a neutral market outcome; it is a squandered opportunity.

The appeal of vashikaran-style content should not be interpreted as evidence of legitimate demand. Rather, it is a diagnostic signal. A market saturated with promises of supernatural intervention, instant success, or effortless transformation reflects conditions of cognitive stress, precarity, and mistrust. Treating such demand as something to be serviced rather than examined abdicates responsibility. Platforms that profit from these signals without addressing their underlying causes participate in the erosion they claim merely to reflect.

A knowledge platform worthy of the name would recognize the difference. It would treat popularity as a metric to be interpreted, not obeyed. It would distinguish between content that increases a listener’s agency and content that exploits uncertainty. Audible’s failure to make this distinction is not a limitation of audio technology or user preference, but a choice about what kinds of intelligence it is willing to cultivate—or neglect—in pursuit of revenue.

\section{Synthesis: Platforms, Knowledge, and the Choice to Degrade}

Taken together, the preceding sections describe not a collection of isolated failures, but a coherent institutional pattern. Audible’s tolerance of fraudulent listings, pseudo-scientific advertisements, AI-generated filler, and misleading representations of authorship is best understood as the outcome of deliberate prioritization under monopoly conditions. Where revenue, infrastructure security, or legal exposure are at stake, enforcement is precise and uncompromising. Where epistemic integrity and human understanding are at stake, standards are allowed to collapse.

This collapse is not technologically necessary. Amazon’s broader ecosystem demonstrates extraordinary capacity for detection, coordination, and control. Nor is it demanded by the medium. Audiobooks, as demonstrated by structured language courses and rigorously designed educational series, can function as instruments of genuine intellectual amplification. The failure, therefore, lies neither in capability nor in form, but in institutional will.

Audible’s marketplace reveals a deeper contradiction at the heart of contemporary platform capitalism. Knowledge is marketed as a premium good, yet treated operationally as interchangeable with noise. Scientific categories are invoked to attract trust, while their semantic content is hollowed out. User captivity substitutes for accountability, and the absence of exit is leveraged to justify indifference. What remains is a system that profits from credibility while declining to defend it.

The cultural consequences of this arrangement extend beyond any single platform. When dominant intermediaries normalize the sale of superstition, manipulation, and algorithmic slop under the banner of books, they reshape expectations about what learning entails. The listener is no longer addressed as a reasoning agent capable of growth, but as a consumer to be managed, placated, or exploited. Over time, this shift dulls standards not only of content, but of attention itself.

If there is a market for vashikaran-style promises, instant wealth schemes, and machine-generated reassurance, that market should be read as a warning signal. It indicates unmet needs for understanding, stability, and agency. A responsible knowledge platform would respond by investing in clarity, pedagogy, and rigor. Audible’s response has been to monetize the signal directly, converting vulnerability into revenue.

The choice facing such platforms is ultimately simple. They may act as stewards of epistemic infrastructure, preserving the distinction between explanation and exploitation. Or they may continue down the path of degradation, selling the appearance of knowledge while eroding its substance. Audible’s current trajectory suggests the latter. Whether that trajectory is altered will determine not merely the quality of its catalog, but the role such platforms play in shaping the intellectual environment of the societies that rely on them.


\newpage
\begin{thebibliography}{99}

\bibitem{Doctorow2023}
Doctorow, C. (2023).
\newblock \emph{The Internet Con: How to Seize the Means of Computation}.
\newblock Verso, London.

\bibitem{Doctorow2023a}
Doctorow, C. (2023).
\newblock The enshittification of TikTok.
\newblock \emph{Pluralistic}.
\newblock \url{https://pluralistic.net}

\bibitem{Khan2017}
Khan, L. (2017).
\newblock Amazon’s antitrust paradox.
\newblock \emph{Yale Law Journal}, 126(3), 710--805.

\bibitem{TeachingCompany}
The Teaching Company. (n.d.).
\newblock \emph{The Great Courses}.
\newblock Chantilly, VA.
\newblock \url{https://www.thegreatcourses.com}

\bibitem{Thomas1998}
Thomas, M. (1998).
\newblock \emph{The Michel Thomas Method}.
\newblock Hodder \& Stoughton, London.

\bibitem{Bohannon2013}
Bohannon, J. (2013).
\newblock Who’s afraid of peer review?
\newblock \emph{Science}, 342(6154), 60--65.


\bibitem{Bender2021}
Bender, E.~M., Gebru, T., McMillan-Major, A., \& Shmitchell, S. (2021).
\newblock On the dangers of stochastic parrots: Can language models be too big?
\newblock \emph{Proceedings of the ACM Conference on Fairness, Accountability, and Transparency}, 610--623.

\bibitem{Frankfurt2005}
Frankfurt, H.~G. (2005).
\newblock \emph{On Bullshit}.
\newblock Princeton University Press, Princeton.

\bibitem{Varian2019}
Varian, H. (2019).
\newblock Artificial intelligence, economics, and industrial organization.
\newblock In A. Agrawal, J. Gans, \& A. Goldfarb (Eds.), \emph{The Economics of Artificial Intelligence}.
\newblock University of Chicago Press.

\bibitem{Wu2018}
Wu, T. (2018).
\newblock \emph{The Curse of Bigness: Antitrust in the New Gilded Age}.
\newblock Columbia Global Reports, New York.

\bibitem{Lynch2016}
Lynch, M. (2016).
\newblock \emph{The Internet of Us: Knowing More and Understanding Less in the Age of Big Data}.
\newblock Liveright, New York.

\bibitem{GawerCusumano2002}
Gawer, A., \& Cusumano, M. (2002).
\newblock \emph{Platform Leadership}.
\newblock Harvard Business School Press, Boston.

\bibitem{Postman1985}
Postman, N. (1985).
\newblock \emph{Amusing Ourselves to Death: Public Discourse in the Age of Show Business}.
\newblock Viking, New York.

\bibitem{Postman1992}
Postman, N. (1992).
\newblock \emph{Technopoly: The Surrender of Culture to Technology}.
\newblock Knopf, New York.

\bibitem{Holt1967}
Holt, J. (1967).
\newblock \emph{How Children Fail}.
\newblock Pitman Publishing, New York.

\bibitem{Holt1976}
Holt, J. (1976).
\newblock \emph{Instead of Education: Ways to Help People Do Things Better}.
\newblock Dutton, New York.

\bibitem{Ellul1964}
Ellul, J. (1964).
\newblock \emph{The Technological Society}.
\newblock Knopf, New York.

\bibitem{Ellul1984}
Ellul, J. (1984).
\newblock \emph{The Humiliation of the Word}.
\newblock Eerdmans, Grand Rapids.

\bibitem{Gopnik2009}
Gopnik, A. (2009).
\newblock \emph{The Philosophical Baby: What Children’s Minds Tell Us About Truth, Love, and the Meaning of Life}.
\newblock Farrar, Straus and Giroux, New York.

\bibitem{Gopnik2016}
Gopnik, A. (2016).
\newblock \emph{The Gardener and the Carpenter: What the New Science of Child Development Tells Us About the Relationship Between Parents and Children}.
\newblock Farrar, Straus and Giroux, New York.

\end{thebibliography}

\end{document}
