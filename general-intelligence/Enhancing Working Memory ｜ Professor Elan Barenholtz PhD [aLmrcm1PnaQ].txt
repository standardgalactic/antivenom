So, there's this big question, why is math so effective in making predictions, and physics, and why in general? Well, physics is really just a mathematization of physical observations, predictions, and why is it so unreasonably good?
And I think the thing we're kind of missing is that math and all the derivative kind of subjects that extend from it is a human artifact that is couched in based on sort of the same,
what appear to be the same core principles as language. Of course, it is itself math and language. It's saying we're going to, what it's doing is self-consciously doing symbolic representation.
But where did we get the idea of symbolic representation? Well, of course, we got it from language. That's a cat over there.
Oh, there's this thing, we can write it down, we can say it, and it picks out an object there, and then we can string these things together to have some representation of the world.
And, you know, math, of course, borrowed this idea from the observation from natural language that you can represent things like, you know, numbers, using certain kinds of symbols.
And then if you string them together in a certain way, and then run certain kinds of operations on them, the thing that speaks back out is going to be some fact about the world as well.
Abstract mathematics ends up not worrying about any sort of actual natural kind physical representation that the numbers represent.
represent necessarily that the symbols are, can just be abstract entities in their own right, but the whole idea of symbolization, playing around with symbols, of course, is borrowed from language.
But I think the unreasonable utility of it is because it's actually derivative of the much greater power of natural language.
Well, let's, let's start actually, let's, let's try to dissolve this kind of divide between long-term and working memory and thinking about these as distinct systems.
Because I don't think that's how it works.
I think we now have a very good model of, of how it works, and it doesn't actually subscribe to this, this, this, this poor notion about what memory is and what it's doing, and therefore this, this divide.
And then, let's think about what the implications might be in relation to what we're actually trying to do.
Because, parenthetically, I'll say that our notion of memory is very deeply tied up in, believe it or not, even if you've never thought about it before, in a sort of a computational framework.
The idea that we're storing a bunch of stuff for later, and then we're, we're going to go ahead and we're going to pull that stuff out and remember it.
And I think that could have very broad implications for thinking about what it would mean to enhance, let's not even call it memory, enhance our performance.
What do we really want?
We really want, in the moment, to do the right thing, to do this sort of functional thing.
And if that requires retrieving information, as we would typically think of it, we want that to work.
We don't really care if, if and when and how it's stored.
What we really care about is runtime.
We want to be able to do the thing that we tend to think memory supports.
We want to be able to generate meaningful responses to questions.
Some of those questions require certain past information making its way into the current moment.
And at that level of generality, everybody wants to enhance their capabilities.
But if you think about it from the wrong standpoint, you might not be thinking about how to do that enhancement correctly either.
Because if what you're thinking of is, like, how do we appropriately store facts, store information, and then later on have the right tools to get that information back,
well, that's going to come with certain kind of regimens, certain ways of thinking about how to solve the problem of enhancing the later performance.
My argument is that that's fundamentally, that's just actually the wrong model.
It's the wrong model for thinking about what the actual process of generating the behaviors we want.
Like when, when I'm talking to you now, and I'm talking about large language models, and I'm talking about memory and enhancement and all of that.
In some ways, I'm obviously using information from the past, right?
That information is, well, this is what we're talking about.
This is the conversation.
And I know what a large language model is because I read about it.
And I programmed them.
And it's certainly true that that information is coming through in what I'm saying right now.
But that doesn't mean that we have to think about it in terms of storing information in this, in this static form.
We want to produce the behavior.
We have a model now that produced the behavior that doesn't store information in this way.
And it does, and when, and at runtime, it's not retrieving anything.
So what are the implications if instead of thinking about runtime performance as storage and retrieval, but just thinking about the performance itself and thinking about that there's this stream of activity that's happening cognitively.
We can think of it as computational level, we can think of it at the mental level, it may have some overlap even with sort of conscious thought, but that's for a later conversation.
But the process is one that we can model in terms of influence rather than memory.
Past events, things that have happened in your long, distant past, things that have happened in your current past, in your more recent past, are influencing your current generation.
Can we call that memory?
Well, sure, in the sense that the system changes in the past and that affects its performance later on.
But is information stored in the traditional sense?
No, because in a large language model, in an artificial neural network, what you've got is just changes in these parameters, changes in the structure, if you want to think about it that way, of the network.
And those changes aren't actually representing some specific set of facts at all.
What they represent is, given a current input right now, what are you going to do about it?
And that input could be, what is the conversation we're having right now?
Well, it's a conversation maybe about large language models and autoregression as well.
Okay.
What's the core thesis?
And I could answer that question.
What's the tenth word that I said, you know, when I started the conversation?
I can't answer that question, but that's yet another thing I can do with this information.
Right?
In other words, what's happened in my recent past has an infinitude of possible outcomes.
And so we can't think in terms of a single static fact that's going to somehow end up coming out of my mouth.
Instead, like a neural network, we're changing things such that we have now a completely different trajectory of how the system is going to go.
So, from a metaphor standpoint, instead of thinking of sort of a computer program or a storage retrieval process, the metaphor that keeps coming to my mind is sort of a stream that's running.
And it's doing stuff along the way, useful stuff.
But if something interacts with that stream, it's going to change the shape that it takes.
And it's going to do so with something like what we'd call memory.
But it's that the information sort of, it sticks around.
It sticks around in the system.
The previous words I said, for example, are influencing what I'm about to say.
And they're still doing it now, right?
The words I just said, you know, 10 words ago, now it's 15 words ago, now it's 20 words ago, are influencing what I'm going to say.
That's what working memory is, in my view.
It's not that there's information that we're going and retrieving.
It's that the past history, and it's non-Markeruvian, the past history is continuing to have an influence on what I'm doing now.
And so, from a standpoint of sort of enhancement, and thinking about how we can improve our runtime performance, what this means is we have to think in terms of how do we nudge the system?
How do we move the system in a direction that gets us where we want to go?
How do we set up sort of the preconditions?
Or we shouldn't even call them preconditions.
It happens in real time.
What can we do to the stream such that it takes the shape, a more optimal shape?
And this is a very different question than thinking about how do we store certain kinds of information with fidelity so that you can later retrieve them accurately.
It's how do we encourage the right kind of influence?
And so, I don't have a clear idea as to how you actually do this kind of manipulation.
But I think a paradigm shift could lead to completely different ways of thinking about these kinds of tools.
What thought tools might exist already, or what's at our disposal that can help us shape that kind of ongoing process?
How can we experiment with that?
How can we introduce information somewhere on the stream?
Where should it be?
You know, is it a minute in that we should introduce some concept that would end up showing up in later thought stream to, and we don't want it to be one specific concept, of course.
But given a particular task ahead of, let's say, you're trying to get somebody to, you're giving them some instructions, and you later on want to produce and be able to carry out some tasks.
Or explain what it is you told them, or explain what it is you told them, right?
These are certain very basic sort of memory-based tasks.
What can we do along the way to potentially influence the outcome as being in the direction you want?
What would enhance, quote-unquote, understanding?
What would that mean?
Well, we could show that this means that somebody's able to produce the task later on more efficiently, maybe more dynamically, maybe more flexibly, so that if something comes along, it doesn't throw them off.
The stream is able to bypass it in a more effective way.
What do these tools look like?
What could they possibly be?
How could we experiment on them?
So I think these are new kinds of questions that we can contemplate now.
Hopefully use some of the existing tools we have in, say, even in the meditation or in just basic mind training, whatever, even your traditional educational toolkit.
How can we take these tools but now use them for actually a radically different task?
So that's, I think, something I'm very interested in exploring and understanding and experimenting with.
And the cool thing is we can do these experiments cheap.
We can kind of run classic experiments.
They would not be, by the way, short-term retrieval memory kind of experiments because those are stupid.
Because what you ask people to do is to explicitly retrieve what happened in the past.
And the whole point of my theory is that that's not actually what we do.
We're influenced by the previous past.
We don't go and retrieve it.
The reason why people studied that was because they were kind of looking where the light is.
And it's a simple thing you can measure.
But it's not a particularly useful thing to measure.
And it's not a particularly useful thing for people to do.
What we really want from memory is to be functional.
What we want from memory is to do the right thing in this circumstance.
In 99.999% of cases, that's not to explicitly recall and retrieve information from the recent past in some form.
It's to be influenced by it.
The things I'm going to say now in this part of the sentence are meaningful and smart because of the beginning of my sentence.
And so we need that influence to come through.
And so we shouldn't be thinking in terms of measurement of explicit retrieval because that was actually a red herring in the first place.
What we need to be doing is thinking in terms of the kinds of retrieval.
But what it really is, is runtime efficacy in doing the kind of stuff we want people to actually be able to do in memory.
And then we measure that.
Like, okay, here's a set of instructions.
Now, carry out the task.
Go, right?
As quickly as you can.
Okay, what if we repeat the instruction?
What if we inject something during the instruction at a certain point?
How does that influence, negatively or positively, the actual capability to keep going with the instruction set?
And we could call this understanding, but we can now see that that's too vague and also too specific a word.
Right?
There's variance.
There's degrees.
It's not like you understand or you don't understand.
The extent to which you're able to finish a sentence meaningfully is not binary.
Like, you either completely forgot what you said in the beginning or you've got it in pristine form.
That is influencing what you're doing.
And so we have to have softer measures that are able to measure sort of efficacy in this way that is not dependent on sort of this binary.
Okay, can you retrieve it or not?
That's far too crude and frankly a misguided measure.
So that's what I think is maybe a really interesting project here.
And it's twofold.
One is to maybe rethink a little bit the kind of things you want to measure.
Because that's not what's historically certainly measured in the so-called short-term memory span window of time.
But that's a really, really important span.
It's like finishing your thoughts.
It's being able to compress in real time.
And these are all conjectures, so I don't even want to commit to this.
But something we're doing right now, when you're listening to me, is you're compressing this stuff.
You're not representing it as the explicit tokens that I'm saying.
You're doing this thing.
But you're doing it in such a way, not that you can retrieve it, right?
Because what the hell did I say 30 seconds ago?
You have no idea.
You can't retrieve it.
But I promise you, it's influencing your understanding of what I'm saying right now and your ability to then respond to it, as long as you know, if you know what I'm talking about.
If you've lost your weight entirely, I apologize.
But if you're still following me here, then the influence is continuing.
And so we have to measure this in a new way.
Psychology needs to think of this in a new way in terms of measurement.
But that's number one, right?
Measurement, capturing what this thing really does.
Even specifically, let's just think of what historically it's thought the short-term memory window.
But we'll start with that.
We can elaborate further.
But that's number one.
How do we capture it?
How do we measure the really interesting, the real thing that we want it to do?
Well, first of all, that it's meaningfully doing.
And then second of all, that we want it to do.
And then once we have what we wanted to do, now we can get to the hard work and maybe, you know, I think it's in some ways more difficult work of, okay, what can we do about it?
What do we, if we have the right measurements, what are the possible interventions that could be helpful in doing it more effectively, in doing it more efficiently?
And, but you need to solve one before you solve two, to some extent, but you can also try to solve these in concert.
Don't wait.
Just try to be more effective right away, right?
We want, you know, we want people to be able to understand information better so they can perform some tasks or explain it back to you.
That's not hard to measure.
We can start with that, start with pretty crude measurements of did this person, was this person able to perform this task based on my narrative description of what they're supposed to do.
And then mess around with that and see if there's a kind of measurable, testable, quantifiable, and settable, you know, parameterizable factors that you can mess around with and then start to see what the impacts are.
Maybe that needs a rethinking.
I almost feel like that's too didactic and too deconstructionist, and maybe that's not the right approach.
But in any case, kind of the work before us, in some sense, is kind of clear.
Exactly how to go about each step, obviously, will take a lot of autoregressing.
All right.
So that's my thoughts for today on this.
I do think it's time for a kind of new psychophysics, and that's going to require a kind of rethinking of what measurement is in this space.
But that's a good thing.
The way we've been doing it hasn't been particularly effective.
And so I think we need to start that today.
Thanks for listening.
I'm on Substack, Generative Brain.
You can also find me at baronholtz.ai.
And I'm also on x slash Twitter.
