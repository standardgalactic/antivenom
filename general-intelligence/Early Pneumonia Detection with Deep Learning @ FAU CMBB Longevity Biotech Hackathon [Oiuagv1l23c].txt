Hello everyone, my name is Shubham and I got my cheapest here, Rekha and Vekki.
I just want you guys to imagine what you can achieve in under a minute.
In one minute you can achieve someone like take a coffee or like, you can see many of you have juice in front of you.
You can drink that. But let me tell you like every 39 seconds, children lose their life to pneumonia.
Every 39 seconds. So here in our project we are trying to detect this pneumonia very early in the stages.
So that they can go to the treatment, they can have proper treatment and they can avoid the damage they have of losing their life.
So what is this cost? An average median cost for the pneumonia treatment in the US itself is like $17,000 as per report.
And it's like from 2012 to 2016 and it might have increased till now.
Like it's 2016, now it's 2025, it might have increased to 80%.
So it's like 25,000 for a year for a normal person to diagnose, you know, and then the amount of bills they pay just to, you know, get rid of that pneumonia charges for them.
And so what we built for the model is like we used a normal CNN, but that's not the end up for us.
Like we just have used an idea planning model where like, you know, we will give the images for them to change.
And then we'll make the predictions and probably we built a normal website for right now.
But in future we have a work where we can incorporate the open source image classification models where we can incorporate, you know, much more diseases related to the lungs itself.
So once we've given the chest texture images, we can not only get the pneumonia, but also some other diseases, even that we can take properly for the images.
So how does it work? So we have like our model on the top. So we have like AI detections like our models and then the LLM models which are going to come later for our model.
And then once the detection is made, we store every file as like, you know, JSON files or any kind of API files and that will push the models to host in some AWS.
Right now we have only the website, we didn't host it in the AWS.
But the future plan for our model is to like post something in the cloud where we can make the continuous integrations.
And, you know, when you get a different outlet, different data sets, we can just trade on them and then have an instant result on that.
It's something like how we take the models and how the website does look like the normal instances without the hostings on the cloud and stuff.
So once you upload a gesture image on the website, it will give you a result whether it's pneumonia or not, or whether it's normal images.
Along with that, it has some recommendations. So right now we have this like a few instructions where you can do without the medicines or all the precautions.
But future, we are like trying to incorporate those like from the, like from the, like from the, like from the, where you can give them a normal, you know,
specifications for them so that they can have different, like, you know, not like, if they have like, let's say, neural areas, you're living very far from the hospitals and stuff.
So you can, you can get the predictions and you can get the recommendations so that you can avoid as far as, you know, like the damages for them.
And also if we use some clear features for the doctor itself, like because the trustworth is one of the most critical factors for the doctors to trust whether they, whether they have AI models or not.
So we are incorporating those experimental AI models so they can have a proper, uh, description of what they just have, like, what is explaining and how the model is predicting whether it's pneumonia or not.
So the doctor can have a proper distance over there.
The doctor can be pushing on over there.
Yeah, that's probably that's it, so I'm just very happy.
Can you rad theチャeal form and how the teachers can see them?
