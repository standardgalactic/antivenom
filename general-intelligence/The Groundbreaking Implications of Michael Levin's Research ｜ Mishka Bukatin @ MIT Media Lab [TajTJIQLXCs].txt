Okay, so I will talk about whether we can embed neural machines into modulating fields and what about this data flow matrix machines I mentioned, you will hear about it some in the talk.
So there is a case for the role of electromagnetic fields in Neura, there is a strong case that electromagnetic fields are important in biological computations.
Then, who is the head of Qualia Research Institute has this conjecture that Qualia actually carried by electromagnetic fields, not by neurons.
And Josh says yesterday that he believes that bodies are untappedness and that's how synchronization is happening.
And this all sort of fits together in the single picture and would explain a lot if it so would be true.
So there are two rules.
There is biorealistic rule, real neural nets, real electromagnetic fields, very important, quite difficult to do.
We would be lucky to understand how C elegans work.
Joshua said the things that we don't understand it.
And that's probably true.
artificial situation might be easier.
And we can be inspired by how we do artificial attention in transformers.
And here small scale efforts have good chance of success.
But we need some guiding light.
We need to think what we are looking for.
So let's compare biological and artificial attention.
Biological attention is this wonderful thing, which works on synchronized oscillations, which are some but not all of gamma waves.
And there is famous Francis Crick and Crick's conjecture that this is how consciousness works.
And artificial attention is very different.
It's just linear combination of feature vectors.
It drops all biological mechanism on the floor, just models the effect.
And what is the effects that some features are emphasized and that some are suppressed.
And surprisingly effective, especially in hierarchies.
At first, I was super unhappy when I first saw it.
With this attention, attention was that, that beautiful thing.
But it turns out that this works well.
So what should be guiding light here?
We want such modulation.
We think that this thing, if they work, they enhance cognition.
And so they should be enable us to do various things better, better training, better inference, better frame tuning.
And artificial fields can be induced by neural machines or they can be external or it can be a mix.
And they can moderate inputs, outputs, connectivity rates and other parameters if there are other parameters.
And that is the new part.
And now I'm going to talk about things which I was talking before in various places.
So, and, but they will be likely to know them is likely to be quite helpful in succeed.
If one wants to succeed at this.
So what's really the true generality of neural model of computation?
You should have alternating linear and non-linear operations.
And the natural degree for that is not streams of numbers.
But any streams which support the operation of combining with numbers, linear combination of some sort.
Not necessarily forming axioms.
And so we can define this neural machines which work by a single unit that says this linear streams.
And they also should have arbitrary and unbounded network size.
And they should be able to modify themselves if you want.
And it's a really, really nice thing.
You take ordinary recurrent neural network where streams of number flow here.
And you generalize it.
And you generalize it to linear streams.
And basically every input works as a little artificial attention device.
And then you get, and there are tons of linear streams.
Streams can be even certain streams of samples of discrete spaces are just fine.
There are also linear streams.
They don't have to do that.
Yeah, I'm watching the clock.
And then this is kind of the machine you have.
And I am going to skip.
If you will work with it, you will want to.
Actually, just like quickly zoom through that.
Is that easy for you?
We'll post all of these.
Okay.
Right.
Yeah.
Yeah.
I'll just, yeah.
Yeah.
So what should one use initially?
One should use something simple.
GPU friendly version where there are just streams of numbers, of matrices, or maybe higher tensors.
But streams of matrices will probably work fine.
And one should explore this modulation visually.
And here I'll tell a couple of things which would help to explore them visually.
Interestingly enough, matrix multiplication is a very geometric visual thing.
You can take monochrome images and interpret them as matrices.
And multiply them and you'll see structure.
You take image of monkey and transpose it.
And this is the symmetric matrix.
It looks like this.
Now, let's normalize like they do in transformers.
Let's softmax normalize rows here.
But let's do also one more thing which they don't do in transformers.
Let's softmax normalize columns on the right matrix.
Then information goes through much better and you have much more fine-grained structure.
And if you start distorting things and want to see which will happen in moderation.
And want to see what this distortion does here.
It's much more reasonable in the second case than the first.
So you should really.
And if you have two different images.
Yes.
Here is also another example.
This is without organization.
And if you normalize this way, then you have all these great structures.
It's very interesting.
And the final remark I want to do for those who know how to do digital audio synthesis,
which everybody did for the last God knows how many years.
These compositions of unit generators are really handcrafted, hand-tuned neural machines.
Small hand-assembled neural machines.
What we do in MaxMSP is neural machines.
With strange neurons, more general than usual.
For example, that would be a typical neuron with three inputs.
Each of them can take its own linear combination.
This is this activation function.
This is one example.
And here we are talking instead of synthesizing order,
we are talking about synthesizing images and animations in the same style,
but the difference is that we use high-dimensional flows,
like flows of matrices instead of flows of numbers.
And that's more or less all I have to say.
Thank you.
Judge's questions?
Yes?
No?
Yes?
No.
Have you come across this idea of morpho computation?
Right.
Yeah.
So with that in mind, how do you think about, you know,
the physical substrate when it comes to computation,
particularly in reference to biological versus artificial?
It's a tangential to what you would think.
No, but yeah.
Biological, yeah.
Biological is certainly mortal, right?
You can't quote them very well, but at least it's extremely difficult
and maybe impossible.
Where this one are very quite capable, which is attractive.
But they also are quite alive, you know,
when you like start doing these experiments.
They are produceable.
Especially with the self-referential.
Yes.
Yes.
Yes.
Yes.
I certainly was seeing tons of emergent properties.
Emergent constellations, which I didn't program.
Emergent sleep wave behavior, all kinds of crazy things.
And, yeah, it's a very, very interesting class of dynamic systems.
Completely unstated.
Wow.
It's like innovative places.
So I highly, highly, very cool.
Thank you.
Thank you.
Thank you.
Thank you.
